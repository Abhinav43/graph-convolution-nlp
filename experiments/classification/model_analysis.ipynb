{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification Model Analysis\n",
    "\n",
    "In this notebook, we analyze the model to understand the effect of graph convolution on the text classification task.\n",
    "\n",
    "* Wha kind of graph structure is effective?\n",
    "  * Node representation\n",
    "  * Edge definition\n",
    "* What kind of connection is effective?\n",
    "  * dependency type etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import matplotlib as plt\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_path():\n",
    "    root = os.path.join(os.path.realpath(\".\"), \"../../\")\n",
    "    if root not in sys.path:\n",
    "        sys.path.append(root)\n",
    "    return root\n",
    "\n",
    "ROOT_DIR = set_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Structure Experiments\n",
    "\n",
    "\n",
    "Node representation\n",
    "\n",
    "* Word embedding only\n",
    "* LSTM before Graph Convolution\n",
    "* LSTM after Graph Convolution\n",
    "\n",
    "LSTM: bidirectional/LSTM\n",
    "\n",
    "Edge kind\n",
    "\n",
    "* Dependency\n",
    "* Similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from gcn.data.multi_nli_dataset import MultiNLIDataset\n",
    "from gcn.classification.trainer import Trainer\n",
    "from gcn.classification.graph_based_classifier import GraphBasedClassifier\n",
    "\n",
    "\n",
    "def experiment(graph_type, lstm, bidirectional=False):\n",
    "    dataset = MultiNLIDataset(ROOT_DIR)\n",
    "    trainer = Trainer(ROOT_DIR, log_dir=\"classifier\")\n",
    "    if graph_type == \"dependency\":\n",
    "        trainer.build_dependency_graph_trainer()        \n",
    "    else:\n",
    "        trainer.build_similarity_graph_trainer()\n",
    "\n",
    "    sequence_length = 25\n",
    "    vocab_size = len(trainer.preprocessor.vocabulary.get())\n",
    "\n",
    "    def preprocessor(x):\n",
    "        _x = trainer.preprocess(x, sequence_length)\n",
    "        values = (_x[\"text\"], _x[\"graph\"])\n",
    "        return values\n",
    "\n",
    "    model = GraphBasedClassifier(vocab_size, sequence_length,\n",
    "                                                        lstm=lstm, bidirectional=bidirectional)\n",
    "    model.build(trainer.num_classes, preprocessor)\n",
    "    metrics = trainer.train(model.model, epochs=25, verbose=0)\n",
    "\n",
    "    result = pd.DataFrame.from_dict(metrics.history)\n",
    "    result.plot.line(secondary_y=[\"loss\", \"val_loss\"])\n",
    "\n",
    "    test_data = dataset.test_data()\n",
    "    y_pred = model.predict(test_data[\"text\"])\n",
    "\n",
    "    print(classification_report(test_data[\"label\"], y_pred,\n",
    "                                target_names=dataset.labels()))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load existing preprocessor preprocessor.pkl.\n"
     ]
    }
   ],
   "source": [
    "model_d = experiment(\"dependency\", lstm=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s = experiment(\"similarity\", lstm=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### +LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_d_b = experiment(\"dependency\", lstm=\"before\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_d_a =experiment(\"dependency\", lstm=\"after\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s_b =experiment(\"similarity\", lstm=\"before\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s_a =experiment(\"similarity\", lstm=\"after\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_d_b_b = experiment(\"dependency\", lstm=\"before\", bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_s_b_b = experiment(\"similarity\", lstm=\"before\", bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
